{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U \"tensorflow-text==2.8.*\"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets,layers,models\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential, load_model\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, Masking, Embedding,Bidirectional\nimport tensorflow_hub as hub\nimport tensorflow_text as text","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-26T13:08:55.782009Z","iopub.execute_input":"2022-12-26T13:08:55.783152Z","iopub.status.idle":"2022-12-26T13:10:15.831968Z","shell.execute_reply.started":"2022-12-26T13:08:55.783033Z","shell.execute_reply":"2022-12-26T13:10:15.830102Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow-text==2.8.*\n  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-text==2.8.*) (0.12.0)\nCollecting tensorflow<2.9,>=2.8.0\n  Downloading tensorflow-2.8.4-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.9/497.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\nCollecting keras<2.9,>=2.8.0rc0\n  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.4.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.15.0)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.12)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\nCollecting libclang>=9.0.1\n  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.12.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\nCollecting tensorboard<2.9,>=2.8\n  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\nCollecting tensorflow-estimator<2.9,>=2.8\n  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.43.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.7.0)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.19.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (59.8.0)\nRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.2.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.28.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.7)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.13.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\nInstalling collected packages: tensorflow-estimator, libclang, keras, tensorflow-io-gcs-filesystem, tensorboard, tensorflow, tensorflow-text\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Uninstalling keras-2.6.0:\n      Successfully uninstalled keras-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.10.1\n    Uninstalling tensorboard-2.10.1:\n      Successfully uninstalled tensorboard-2.10.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.8.4 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.8.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.8.4 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.8.4 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.29.0 which is incompatible.\npytorch-lightning 1.7.7 requires tensorboard>=2.9.1, but you have tensorboard 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.8.0 libclang-14.0.6 tensorboard-2.8.0 tensorflow-2.8.4 tensorflow-estimator-2.8.0 tensorflow-io-gcs-filesystem-0.29.0 tensorflow-text-2.8.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2022-12-26 13:10:09.560048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-12-26 13:10:09.560098: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"# download glove and unzip it in Notebook.\n!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove*.zip.1\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:15.834189Z","iopub.execute_input":"2022-12-26T13:10:15.835164Z","iopub.status.idle":"2022-12-26T13:10:15.845167Z","shell.execute_reply.started":"2022-12-26T13:10:15.835123Z","shell.execute_reply":"2022-12-26T13:10:15.843630Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'# download glove and unzip it in Notebook.\\n!wget http://nlp.stanford.edu/data/glove.6B.zip\\n!unzip glove*.zip.1'"},"metadata":{}}]},{"cell_type":"code","source":"def embedding_for_vocab(filepath, word_index,embedding_dim):\n    vocab_size = len(word_index) + 1\n    # Adding again 1 because of reserved 0 index\n    embedding_matrix_vocab = np.zeros((vocab_size,embedding_dim))\n    with open(filepath,encoding=\"utf8\") as f:\n        for line in f:\n            word, *vector = line.split()\n            if word in word_index:\n                idx = word_index[word]\n                embedding_matrix_vocab[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n    return embedding_matrix_vocab","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:15.846653Z","iopub.execute_input":"2022-12-26T13:10:15.846954Z","iopub.status.idle":"2022-12-26T13:10:15.874128Z","shell.execute_reply.started":"2022-12-26T13:10:15.846925Z","shell.execute_reply":"2022-12-26T13:10:15.872215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n    plt.plot(history.history['precision'])\n    plt.plot(history.history['val_precision'])\n    plt.title('model precision')\n    plt.ylabel('Precision')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\ndef plot_train(train_images,class_names,train_labels):\n    plt.figure(figsize=(20,10))\n    for i in range(5):\n        plt.subplot(5,2,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(train_images[i],cmap=plt.cm.binary)\n        # The CIFAR labels happen to be arrays,# which is why you need the extra index\n        plt.xlabel(class_names[train_labels[i]])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:15.876791Z","iopub.execute_input":"2022-12-26T13:10:15.877383Z","iopub.status.idle":"2022-12-26T13:10:15.888208Z","shell.execute_reply.started":"2022-12-26T13:10:15.877324Z","shell.execute_reply":"2022-12-26T13:10:15.887304Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"datas = pd.read_csv(\"/kaggle/input/goemotions/GoEmotions.csv\")\ndata = datas.drop(['id','author','subreddit','link_id','parent_id','rater_id','created_utc'],axis=1)\ndata = data[data['example_very_unclear']==False]\ndata = data.drop_duplicates('text')\ndata = data[data[\"neutral\"]==0].drop(['neutral','example_very_unclear'],axis=1)\ndata.describe(include=\"all\")","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:15.890407Z","iopub.execute_input":"2022-12-26T13:10:15.891658Z","iopub.status.idle":"2022-12-26T13:10:18.280512Z","shell.execute_reply.started":"2022-12-26T13:10:15.891574Z","shell.execute_reply":"2022-12-26T13:10:18.278710Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                   text    admiration     amusement         anger  \\\ncount             41927  41927.000000  41927.000000  41927.000000   \nunique            41927           NaN           NaN           NaN   \ntop     That game hurt.           NaN           NaN           NaN   \nfreq                  1           NaN           NaN           NaN   \nmean                NaN      0.116250      0.064016      0.053474   \nstd                 NaN      0.320528      0.244784      0.224979   \nmin                 NaN      0.000000      0.000000      0.000000   \n25%                 NaN      0.000000      0.000000      0.000000   \n50%                 NaN      0.000000      0.000000      0.000000   \n75%                 NaN      0.000000      0.000000      0.000000   \nmax                 NaN      1.000000      1.000000      1.000000   \n\n           annoyance      approval        caring     confusion     curiosity  \\\ncount   41927.000000  41927.000000  41927.000000  41927.000000  41927.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.084289      0.116822      0.038424      0.048251      0.066974   \nstd         0.277825      0.321212      0.192220      0.214298      0.249979   \nmin         0.000000      0.000000      0.000000      0.000000      0.000000   \n25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n75%         0.000000      0.000000      0.000000      0.000000      0.000000   \nmax         1.000000      1.000000      1.000000      1.000000      1.000000   \n\n              desire  ...           joy          love   nervousness  \\\ncount   41927.000000  ...  41927.000000  41927.000000  41927.000000   \nunique           NaN  ...           NaN           NaN           NaN   \ntop              NaN  ...           NaN           NaN           NaN   \nfreq             NaN  ...           NaN           NaN           NaN   \nmean        0.024185  ...      0.052591      0.056527      0.011663   \nstd         0.153625  ...      0.223219      0.230939      0.107366   \nmin         0.000000  ...      0.000000      0.000000      0.000000   \n25%         0.000000  ...      0.000000      0.000000      0.000000   \n50%         0.000000  ...      0.000000      0.000000      0.000000   \n75%         0.000000  ...      0.000000      0.000000      0.000000   \nmax         1.000000  ...      1.000000      1.000000      1.000000   \n\n            optimism         pride   realization        relief       remorse  \\\ncount   41927.000000  41927.000000  41927.000000  41927.000000  41927.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.058387      0.008443      0.056885      0.008873      0.017030   \nstd         0.234477      0.091499      0.231625      0.093777      0.129383   \nmin         0.000000      0.000000      0.000000      0.000000      0.000000   \n25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n75%         0.000000      0.000000      0.000000      0.000000      0.000000   \nmax         1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             sadness      surprise  \ncount   41927.000000  41927.000000  \nunique           NaN           NaN  \ntop              NaN           NaN  \nfreq             NaN           NaN  \nmean        0.044148      0.036444  \nstd         0.205427      0.187395  \nmin         0.000000      0.000000  \n25%         0.000000      0.000000  \n50%         0.000000      0.000000  \n75%         0.000000      0.000000  \nmax         1.000000      1.000000  \n\n[11 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>curiosity</th>\n      <th>desire</th>\n      <th>...</th>\n      <th>joy</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>41927</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>...</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n      <td>41927.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>41927</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>That game hurt.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>0.116250</td>\n      <td>0.064016</td>\n      <td>0.053474</td>\n      <td>0.084289</td>\n      <td>0.116822</td>\n      <td>0.038424</td>\n      <td>0.048251</td>\n      <td>0.066974</td>\n      <td>0.024185</td>\n      <td>...</td>\n      <td>0.052591</td>\n      <td>0.056527</td>\n      <td>0.011663</td>\n      <td>0.058387</td>\n      <td>0.008443</td>\n      <td>0.056885</td>\n      <td>0.008873</td>\n      <td>0.017030</td>\n      <td>0.044148</td>\n      <td>0.036444</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>0.320528</td>\n      <td>0.244784</td>\n      <td>0.224979</td>\n      <td>0.277825</td>\n      <td>0.321212</td>\n      <td>0.192220</td>\n      <td>0.214298</td>\n      <td>0.249979</td>\n      <td>0.153625</td>\n      <td>...</td>\n      <td>0.223219</td>\n      <td>0.230939</td>\n      <td>0.107366</td>\n      <td>0.234477</td>\n      <td>0.091499</td>\n      <td>0.231625</td>\n      <td>0.093777</td>\n      <td>0.129383</td>\n      <td>0.205427</td>\n      <td>0.187395</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:18.283476Z","iopub.execute_input":"2022-12-26T13:10:18.283821Z","iopub.status.idle":"2022-12-26T13:10:18.307750Z","shell.execute_reply.started":"2022-12-26T13:10:18.283795Z","shell.execute_reply":"2022-12-26T13:10:18.305999Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text  admiration  amusement  \\\n0                                    That game hurt.           0          0   \n3                                 Man I love reddit.           0          0   \n5  Right? Considering it’s such an important docu...           0          0   \n6  He isn't as big, but he's still quite popular....           0          0   \n7  That's crazy; I went to a super [RELIGION] hig...           0          1   \n\n   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  joy  \\\n0      0          0         0       0          0          0       0  ...    0   \n3      0          0         0       0          0          0       0  ...    0   \n5      0          0         0       0          0          0       0  ...    0   \n6      0          0         0       0          0          0       0  ...    0   \n7      0          0         0       0          0          0       0  ...    0   \n\n   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n0     0            0         0      0            0       0        0        1   \n3     1            0         0      0            0       0        0        0   \n5     0            0         0      0            0       0        0        0   \n6     0            0         0      0            0       0        0        0   \n7     0            0         0      0            0       0        0        0   \n\n   surprise  \n0         0  \n3         0  \n5         0  \n6         0  \n7         0  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>curiosity</th>\n      <th>desire</th>\n      <th>...</th>\n      <th>joy</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>That game hurt.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Man I love reddit.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Right? Considering it’s such an important docu...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>He isn't as big, but he's still quite popular....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>That's crazy; I went to a super [RELIGION] hig...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#data[(data['disapproval']==data['joy']) & (data['joy']==1)] #some texts have multiple emotions","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:18.309595Z","iopub.execute_input":"2022-12-26T13:10:18.309969Z","iopub.status.idle":"2022-12-26T13:10:18.316740Z","shell.execute_reply.started":"2022-12-26T13:10:18.309937Z","shell.execute_reply":"2022-12-26T13:10:18.314644Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"data = data[np.sum(datadrop('text',axis=1),axis=1)<=1]\ndata.describe()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:18.318550Z","iopub.execute_input":"2022-12-26T13:10:18.318846Z","iopub.status.idle":"2022-12-26T13:10:18.330491Z","shell.execute_reply.started":"2022-12-26T13:10:18.318819Z","shell.execute_reply":"2022-12-26T13:10:18.329410Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"data = data[np.sum(datadrop('text',axis=1),axis=1)<=1]\\ndata.describe()\""},"metadata":{}}]},{"cell_type":"code","source":"#tokenize\ntokenizer = Tokenizer(\n    num_words=None,\n    lower = False,\n    split=' '\n)\nabst = data['text'].values\ntokenizer.fit_on_texts(abst)\nsequences = tokenizer.texts_to_sequences(abst)\n\n#pad sequences so they all have same lengths\nsequences = tf.keras.preprocessing.sequence.pad_sequences(\n    sequences,\n    maxlen=max([len(i) for i in sequences]),padding='post')\nsequences[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:18.333082Z","iopub.execute_input":"2022-12-26T13:10:18.333437Z","iopub.status.idle":"2022-12-26T13:10:20.321257Z","shell.execute_reply.started":"2022-12-26T13:10:18.333406Z","shell.execute_reply":"2022-12-26T13:10:20.319973Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([ 83, 140, 537,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"text, labels = data['text'], data.drop('text',axis=1).values\nfeatures = np.array([item for item in [seq for seq in sequences]])\nfeatures[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.324736Z","iopub.execute_input":"2022-12-26T13:10:20.325057Z","iopub.status.idle":"2022-12-26T13:10:20.362395Z","shell.execute_reply.started":"2022-12-26T13:10:20.325031Z","shell.execute_reply":"2022-12-26T13:10:20.361311Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([ 83, 140, 537,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(features, labels, test_size = 0.2, random_state=23)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.363894Z","iopub.execute_input":"2022-12-26T13:10:20.364222Z","iopub.status.idle":"2022-12-26T13:10:20.389448Z","shell.execute_reply.started":"2022-12-26T13:10:20.364195Z","shell.execute_reply":"2022-12-26T13:10:20.388173Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(33541, 34)"},"metadata":{}}]},{"cell_type":"code","source":"Y_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.390851Z","iopub.execute_input":"2022-12-26T13:10:20.391163Z","iopub.status.idle":"2022-12-26T13:10:20.399747Z","shell.execute_reply.started":"2022-12-26T13:10:20.391136Z","shell.execute_reply":"2022-12-26T13:10:20.398334Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n#build model\ndef create_model(training_length,num_words,embedding_matrix=[]):\n   \n    # Embedding layer\n    if len(embedding_matrix)>0:\n        model = Sequential()\n        model.add(\n        Embedding(input_dim=num_words,\n                  input_length = training_length,\n                  output_dim=300,\n                  weights=[embedding_matrix],\n                  trainable=False,\n                  mask_zero=False))\n            # Recurrent layer\n        model.add(Dropout(0.2))\n        model.add(Bidirectional(CuDNNLSTM(128, return_sequences=False)))\n        # Fully connected layer\n        model.add(Dense(64, activation='tanh'))\n        model.add(Dropout(0.3))\n\n        # Output layer\n        model.add(Dense(27, activation='sigmoid'))\n        # Masking layer for pre-trained embeddings\n        #model.add(Masking(mask_value=0.0))\n    else:\n        bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n        bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\")\n\n        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='inputs')\n        preprocessed_text = bert_preprocess(text_input)\n        outputs = bert_encoder(preprocessed_text)\n        l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n        l = tf.keras.layers.Dense(27, activation='sigmoid', name=\"output\")(l)\n        model = tf.keras.Model(inputs=[text_input], outputs = [l])\n\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.401485Z","iopub.execute_input":"2022-12-26T13:10:20.401896Z","iopub.status.idle":"2022-12-26T13:10:20.813726Z","shell.execute_reply.started":"2022-12-26T13:10:20.401858Z","shell.execute_reply":"2022-12-26T13:10:20.812053Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"embedding_matrix_vocab = embedding_for_vocab('./glove.6B.300d.txt', tokenizer.word_index,300)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.815900Z","iopub.execute_input":"2022-12-26T13:10:20.816311Z","iopub.status.idle":"2022-12-26T13:10:20.823567Z","shell.execute_reply.started":"2022-12-26T13:10:20.816281Z","shell.execute_reply":"2022-12-26T13:10:20.822255Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"embedding_matrix_vocab = embedding_for_vocab('./glove.6B.300d.txt', tokenizer.word_index,300)\""},"metadata":{}}]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index)+1","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.824937Z","iopub.execute_input":"2022-12-26T13:10:20.825548Z","iopub.status.idle":"2022-12-26T13:10:20.834998Z","shell.execute_reply.started":"2022-12-26T13:10:20.825518Z","shell.execute_reply":"2022-12-26T13:10:20.834032Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_precision', mode='max', verbose=1, patience=10)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.836292Z","iopub.execute_input":"2022-12-26T13:10:20.837232Z","iopub.status.idle":"2022-12-26T13:10:20.849132Z","shell.execute_reply.started":"2022-12-26T13:10:20.837195Z","shell.execute_reply":"2022-12-26T13:10:20.847412Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(data['text'],data.drop(['text'],axis=1),  test_size = 0.2, random_state=23)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.850977Z","iopub.execute_input":"2022-12-26T13:10:20.851475Z","iopub.status.idle":"2022-12-26T13:10:20.886014Z","shell.execute_reply.started":"2022-12-26T13:10:20.851442Z","shell.execute_reply":"2022-12-26T13:10:20.884328Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.888264Z","iopub.execute_input":"2022-12-26T13:10:20.888688Z","iopub.status.idle":"2022-12-26T13:10:20.900985Z","shell.execute_reply.started":"2022-12-26T13:10:20.888651Z","shell.execute_reply":"2022-12-26T13:10:20.897583Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 3442982412109294890\nxla_global_id: -1\n]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-26 13:10:20.890655: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-26 13:10:20.892490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-12-26 13:10:20.892522: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n2022-12-26 13:10:20.892559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cef69629effa): /proc/driver/nvidia/version does not exist\n","output_type":"stream"}]},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy(['gpu:0','gpu:1'])\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntrain_dataset = train_dataset.with_options(options).batch(1000).prefetch(tf.data.AUTOTUNE)\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\nval_dataset = val_dataset.with_options(options).batch(1000)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:20.903527Z","iopub.execute_input":"2022-12-26T13:10:20.904283Z","iopub.status.idle":"2022-12-26T13:10:21.000668Z","shell.execute_reply.started":"2022-12-26T13:10:20.904237Z","shell.execute_reply":"2022-12-26T13:10:20.999748Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Number of devices: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:10:21.002949Z","iopub.execute_input":"2022-12-26T13:10:21.003406Z","iopub.status.idle":"2022-12-26T13:10:21.010651Z","shell.execute_reply.started":"2022-12-26T13:10:21.003335Z","shell.execute_reply":"2022-12-26T13:10:21.009736Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 27), dtype=tf.int64, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"# Open a strategy scope.\nwith strategy.scope():\n  # Everything that creates variables should be under the strategy scope.\n  # In general this is only model construction & `compile()`.\n    model = create_model(34,vocab_size)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=tf.keras.metrics.Precision(name='precision'))\n    model.summary()\n    history = model.fit(train_dataset,epochs=5,\n                    validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-24T11:15:33.619612Z","iopub.execute_input":"2022-12-24T11:15:33.619986Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inputs (InputLayer)            [(None,)]            0           []                               \n                                                                                                  \n keras_layer_9 (KerasLayer)     {'input_word_ids':   0           ['inputs[0][0]']                 \n                                (None, 128),                                                      \n                                 'input_mask': (Non                                               \n                                e, 128),                                                          \n                                 'input_type_ids':                                                \n                                (None, 128)}                                                      \n                                                                                                  \n keras_layer_10 (KerasLayer)    {'sequence_output':  28763649    ['keras_layer_9[0][0]',          \n                                 (None, None, 512),               'keras_layer_9[0][1]',          \n                                 'default': (None,                'keras_layer_9[0][2]']          \n                                512),                                                             \n                                 'pooled_output': (                                               \n                                None, 512),                                                       \n                                 'encoder_outputs':                                               \n                                 [(None, None, 512)                                               \n                                , (None, None, 512)                                               \n                                , (None, None, 512)                                               \n                                , (None, None, 512)                                               \n                                ]}                                                                \n                                                                                                  \n dropout (Dropout)              (None, 512)          0           ['keras_layer_10[0][5]']         \n                                                                                                  \n output (Dense)                 (None, 27)           13851       ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 28,777,500\nTrainable params: 13,851\nNon-trainable params: 28,763,649\n__________________________________________________________________________________________________\nEpoch 1/5\n34/34 [==============================] - 863s 25s/step - loss: 0.3101 - precision: 0.0387 - val_loss: 0.1883 - val_precision: 0.0000e+00\nEpoch 2/5\n34/34 [==============================] - 869s 26s/step - loss: 0.1837 - precision: 0.1818 - val_loss: 0.1788 - val_precision: 1.0000\nEpoch 3/5\n34/34 [==============================] - 885s 26s/step - loss: 0.1775 - precision: 0.6364 - val_loss: 0.1743 - val_precision: 0.9167\nEpoch 4/5\n34/34 [==============================] - 868s 26s/step - loss: 0.1734 - precision: 0.8105 - val_loss: 0.1709 - val_precision: 0.9242\nEpoch 5/5\n34/34 [==============================] - ETA: 0s - loss: 0.1702 - precision: 0.8249 ","output_type":"stream"}]},{"cell_type":"code","source":"plot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.saved_model.load('/kaggle/input/goemon')","metadata":{"execution":{"iopub.status.busy":"2022-12-26T13:47:32.419765Z","iopub.execute_input":"2022-12-26T13:47:32.420221Z","iopub.status.idle":"2022-12-26T13:47:32.454092Z","shell.execute_reply.started":"2022-12-26T13:47:32.420185Z","shell.execute_reply":"2022-12-26T13:47:32.453038Z"},"trusted":true},"execution_count":26,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/107915140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/goemon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 949\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   debug_info_path = file_io.join(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     raise IOError(\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         f\"{constants.SAVED_MODEL_FILENAME_PB}}}\")\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /kaggle/input/goemon/{saved_model.pbtxt|saved_model.pb}"],"ename":"OSError","evalue":"SavedModel file does not exist at: /kaggle/input/goemon/{saved_model.pbtxt|saved_model.pb}","output_type":"error"}]},{"cell_type":"code","source":"pred = model.predict(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prob(x):\n    if x>0.5:\n        return 1\n    return 0\nmap(prob,pred[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = [list(map(prob,i)) for i in pred]","metadata":{"execution":{"iopub.status.busy":"2022-12-23T18:42:42.965319Z","iopub.execute_input":"2022-12-23T18:42:42.965641Z","iopub.status.idle":"2022-12-23T18:42:43.476862Z","shell.execute_reply.started":"2022-12-23T18:42:42.965617Z","shell.execute_reply":"2022-12-23T18:42:43.475901Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"idx = tokenizer.index_word\nphrase = ' '.join(idx[w] for w in X_val[0] if w!=0)\nprint(phrase,Y_val[0],pred[0])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-23T18:42:44.912962Z","iopub.execute_input":"2022-12-23T18:42:44.913829Z","iopub.status.idle":"2022-12-23T18:42:44.922928Z","shell.execute_reply.started":"2022-12-23T18:42:44.913794Z","shell.execute_reply":"2022-12-23T18:42:44.921918Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"NAME completely unpredictable Bunch of them were standing together in the middle of the ring lol [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix([np.argmax(i) for i in Y_train],pred)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T14:45:21.514462Z","iopub.execute_input":"2022-12-20T14:45:21.515619Z","iopub.status.idle":"2022-12-20T14:45:21.581168Z","shell.execute_reply.started":"2022-12-20T14:45:21.515563Z","shell.execute_reply":"2022-12-20T14:45:21.580100Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"array([[2243,   60,  321,   99,   89,    8,    1,   21,    2,    2,   25,\n           0,    0,   27,    2,   46,    0,   12,   21,    0,   11,    2,\n          20,    0,    0,    7,   11],\n       [   8, 1292,   28,    9,    2,    0,    0,    2,    0,    0,    5,\n           0,    0,    3,    0,    3,    0,    3,    5,    0,    3,    1,\n           1,    0,    1,    1,    0],\n       [   6,    6, 1026,   12,    2,    2,    1,    2,    2,    0,    4,\n           2,    0,    4,    1,   13,    1,    0,    3,    0,    0,    0,\n           3,    0,    0,    2,    0],\n       [   7,   11,   30, 1583,    4,    3,    0,    3,    0,    2,    2,\n           1,    3,    1,    0,    1,    0,    2,    1,    0,    4,    0,\n           0,    0,    0,    4,    0],\n       [  30,   22,   30,    8, 2222,    6,    0,    2,    4,    6,   22,\n           1,    2,    8,    1,   12,    1,   10,   11,    0,   26,    3,\n          15,    2,    1,    4,    1],\n       [   6,    4,    8,    2,    1,  691,    0,    0,    0,    0,    1,\n           0,    0,    1,    0,    9,    0,    0,    1,    0,    4,    0,\n           3,    0,    2,    2,    0],\n       [   9,   10,   19,    9,    5,    4,  912,   11,    1,    4,   16,\n           2,    2,    6,    1,   10,    0,    4,    3,    0,    6,    0,\n          29,    0,    2,    4,    3],\n       [   5,    8,   25,    2,    2,    0,    5, 1262,    0,    2,    7,\n           0,    1,    3,    0,   12,    0,    1,    3,    0,    7,    0,\n           2,    0,    0,    0,    1],\n       [   2,    3,   12,    1,    1,    2,    0,    0,  408,    0,    3,\n           1,    0,    2,    0,    3,    0,    1,    1,    0,   11,    0,\n           2,    1,    0,    0,    1],\n       [   0,    8,    8,   11,    1,    2,    0,    1,    1,  893,    3,\n           3,    1,    0,    0,    1,    0,    2,    1,    0,    2,    0,\n           4,    0,    1,    5,    0],\n       [   3,    2,   21,    4,    1,    0,    1,    6,    0,    2, 1560,\n           1,    2,    1,    0,    3,    0,    2,    6,    0,    9,    1,\n           5,    1,    0,    4,    0],\n       [   3,    1,   10,    7,    2,    0,    0,    1,    1,    2,    5,\n         521,    0,    0,    0,    1,    0,    2,    0,    0,    1,    0,\n           2,    0,    1,    0,    0],\n       [   1,    3,    3,    5,    1,    1,    2,    0,    0,    0,    5,\n           0,  237,    0,    0,    2,    0,    1,    0,    0,    1,    0,\n           3,    1,    2,    0,    0],\n       [  14,    6,   35,    1,    8,    2,    1,    0,    2,    0,    1,\n           0,    1,  517,    0,   16,    0,    9,   10,    0,    0,    0,\n           3,    0,    0,    1,    0],\n       [   1,    2,    6,    3,    0,    4,    0,    3,    0,    1,    3,\n           3,    0,    1,  334,    1,    0,    1,    0,    1,    2,    0,\n           0,    0,    0,    1,    2],\n       [  15,    3,   39,    5,    0,    3,    0,    2,    1,    2,    4,\n           0,    0,    4,    0, 1581,    0,    7,    3,    0,    3,    0,\n           0,    3,    0,    1,    0],\n       [   0,    1,    1,    0,    0,    2,    0,    1,    0,    0,    3,\n           0,    0,    0,    0,    0,   63,    0,    0,    0,    1,    1,\n           0,    0,    1,    1,    0],\n       [  12,   23,   14,    6,    2,    2,    0,    0,    1,    1,    4,\n           1,    0,    8,    0,    8,    0,  822,   11,    0,    3,    0,\n           1,    0,    0,    0,    0],\n       [  11,    5,   22,    0,    0,    1,    0,    2,    1,    0,    1,\n           1,    1,    2,    0,    8,    0,    5, 1035,    0,    1,    0,\n           1,    0,    0,    3,    0],\n       [   0,    3,    4,    1,    0,    3,    0,    0,    0,    1,    1,\n           0,    0,    0,    0,    0,    0,    1,    0,  136,    4,    0,\n           0,    0,    0,    1,    2],\n       [   4,    4,    6,    1,    0,    2,    0,    0,    1,    0,    0,\n           0,    0,    1,    0,    6,    0,    5,    1,    0,  960,    0,\n           0,    0,    0,    0,    0],\n       [   8,    3,    2,    1,    1,    3,    0,    2,    0,    0,    5,\n           1,    0,    0,    0,    1,    0,    0,    0,    0,    1,  115,\n           2,    1,    0,    0,    0],\n       [   2,    2,    7,    2,    3,    1,    1,    3,    0,    4,    4,\n           1,    0,    0,    0,    7,    0,    5,    2,    0,    6,    0,\n         935,    0,    1,    1,    0],\n       [   2,    1,    1,    0,    4,    5,    1,    1,    1,    3,    1,\n           0,    0,    0,    0,    2,    0,    1,    1,    0,    6,    0,\n           1,  148,    0,    1,    0],\n       [   2,    2,    5,    1,    2,    1,    1,    0,    1,    3,    2,\n           0,    0,    0,    0,    3,    0,    0,    0,    0,    1,    0,\n           2,    0,  287,    2,    0],\n       [   1,    8,   18,    5,    1,    2,    0,    1,    0,    3,    8,\n           1,    0,    1,    0,    4,    1,    1,    1,    0,    2,    0,\n           2,    0,    5,  727,    0],\n       [   8,   13,   28,    4,    1,    0,    0,    1,    0,    0,    3,\n           1,    0,    2,    1,    3,    0,    1,    0,    0,    6,    2,\n           3,    0,    0,    2,  656]])"},"metadata":{}}]},{"cell_type":"code","source":"modele.save(\"goemotions.h5\")","metadata":{},"execution_count":null,"outputs":[]}]}